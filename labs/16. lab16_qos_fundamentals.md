# Quality of Service (QoS) Fundamentals

When it comes to your computer, the Task Manager is your immediate response when an application hangs or becomes unresponsive. You can “end a task” (application), freeing up your computer’s resources to apply to other applications. Similarly, **Quality of Service (QoS)** refers to tools that networking devices use to treat packets on the network differently as they pass through a device. Both act as the “managers” of resources, determining what is and isn’t important based on prioritization.

In this lab, we’ll explore how network devices identify, classify, and prioritize traffic using QoS mechanisms. The CCNA doesn’t go into QoS in depth. Conceptually, making this is a perfect opportunity to apply these ideas of QoS for the homelab.

For this lab, we will go over:

1. **Understanding QoS**
2. **Three Main QoS Models**
3. **Classification and Marking**
4. **Queue Behavior**
5. **Traffic Shaping and Policing**
6. **Congestion Avoidance**
7. **Wrap-Up**

## **Understanding QoS**

If we treated all traffic equally, our idea of phone calls, video calls, and interactive traffic would struggle to work effectively. This concept is called **Best Effort Delivery**, meaning there are no guarantees that traffic will be delivered reliably. This comes to our main idea of QoS: all traffic on a network is not equal, and we need to prioritize it. 

There are four characteristics of network traffic:

- **Bandwidth** - The speed/capacity of a link, and how many bits per second can be sent.
- **Delay** - The time it takes to send/receive packets back, to and from a host.
- **Jitter** - Variation in one-way delay between two applications.
- **Loss** - Total number of lost packets (usually a percentage).

Let’s take a look at the different types of traffic that QoS should affect on a network:

| **Traffic Type** | **Sensitivity** | **Example** |
| --- | --- | --- |
| Voice | Delay & Jitter | VoIP Phones |
| Video | Delay & Loss | Zoom, FaceTime |
| Critical Data | Loss | Database Traffic |
| Best Effort | None | Web Browsing, Email |

With a better understanding of how different types of traffic are affected by their sensitivity to traffic characteristics, we can see why QoS is crucial for ensuring reliable delivery of priority traffic on the network. Let’s now take a look at the different QoS models there are and how they may or may not apply to networks today.

## **Three Main QoS Models**

Right now, there are three different QoS models: **Best Effort**, **Integrated Services (IntServ)**, and **Differentiated Services (DiffServ)**. Let me explain the differences between these models:

- **Best Effort**: Providing no QoS, packets are treated the same with no bounds on delay, jitter, or loss.
- **Integrated Services (IntServ)**: Great for resource reservation, allowing specific amounts of bandwidth using the protocol **Resource Reservation Protocol (RSVP)**. Not scalable, so it isn’t used much today.
- **Differentiated Services (DiffServ)**: A modern, scalable, and flexible model that classifies traffic into different classes using the **Differentiated Services Code Points (DSCP)** protocol to mark packets.

Here’s a summary table comparing each of the QoS models:

| **Model** | **Description** | **Example** |
| --- | --- | --- |
| Best-Effort | No QoS - traffic is treated equally. | Default Networks |
| Integrated Services (IntServ) | Per-flow Reservations using RSVP | Older VoIP/Legacy WAN |
| Differentiated Services (DiffServ) | Traffic marked and prioritized by DSCP | Modern Enterprise Networks |

Since DiffServ is the most utilized QoS model today, and the main focal point of the CCNA, we will use this model for further QoS concepts. Let’s take a look next at how marking works with DiffServ.

## **Classification and Marking**

DiffServ utilizes classification and marking to classify packets, based on their header contents, and then marks them by changing bits in their specified header:

- **Classification**: The process of matching fields in a message to make a QoS action.
    - Similar to how an ACL matches packet headers (classify), and then has the action to choose if a packet needs to be discarded.
- **Marking**: QoS tools will change one or more header fields, setting a value in the header to differentiate the packet for QoS processing.

The way that DiffServ does it is by DSCP (IP marking) and CoS (Ethernet marking) for Layer 3 and Layer 2, respectively. Let’s take a look at each concept next:

### CoS Marking

Existing in the 802.1Q header, only existing on trunked links, we have the fields that make up the Ethernet frame:

- **Class of Service (CoS)**: Sitting in the third byte of the 4-byte 802.1Q header, CoS supplies eight possible values to mark.

Here’s a look at an Ethernet frame with the 802.1Q header:

<center>
  <img width="400" height="400" alt="802.1q_header" class="center" src="https://github.com/user-attachments/assets/75c7b831-6d87-4923-8f85-edf588dc0a52" />
</center>

- Inside the frame, we have the two main fields:
    - **Tag Protocol Identifier (TPID)**
    - **Tag Control Information (TCI)**
    

- The TCI is a 2-byte, or 16-bit field that is comprised of these three fields:
    - **Priority Code Point (PCP)**
    - **Drop Eligible Indicator (DEI)**
    - **VLAN Identifier (VLAN ID)**

Without going into major depth, PCP is the 3-bit field that is utilized to mark IP packet headers for CoS. Depending on the packet value determines what type of priority is given to the Ethernet frame entirely. However, what if we’re not traveling over an 802.1Q link? That’s where QoS marking on the Layer 3 comes into play.

### DSCP Marking

Offering a more persistent marking strategy from source to destination, let’s see how Layer 3 offers CoS:

Inside the IPv4 packet, we have the 8-bit Type of Service (ToS) field. Inside houses:

- **IP Precedence (IPP)**: A 3-bit field that is used for marking. IPP values are 0-7, determining different traffic classes of service.
    - Keep in mind that DSCP has redefined the ToS field, making IPP obsolete.

Here’s a look at an IPv4 Packet with the ToS field:

<center>
  <img width="400" height="400" alt="tos_field" class="center" src="https://github.com/user-attachments/assets/118c229d-8905-4ce1-9a13-e4a7ba2d44c2" />
</center>

Below the IPP field are the 8-bit DiffServ fields. Made up of the following:

- **Explicit Congestion Notification (ECN)**: A 2-bit field used to determine the Flow Control (windowing) of TCP connections to prevent packet loss.
- **Differentiated Services Code Point (DSCP)**: A 6-bit field in the IP header used to mark a value in the header for the purpose of performing QoS actions on the packet.

All in all, both CoS and DSCP help with marking at Layer 2 and Layer 3. Mostly trying to help the routers know how to treat each packet like cars on the highway exiting at their correct exit ramp.

### **Trust Boundaries**

Now that we understand CoS and DSCP, knowing where in our network they should be explicitly trusted and not trusted is important. This especially applies to end-hosts. 

- **Trust Boundaries**: The point in the path a packet can trust the current QoS markings.

For instance, if voice is the most prioritized traffic in our network, we wouldn’t want a user to be able to adjust the DSCP of their traffic to match voice, so they get better QoS treatment.

Here is a perfect example of how Trust Boundaries are set:

<center>
  <img width="400" height="400" alt="trust_boundry" class="center" src="https://github.com/user-attachments/assets/362a63d5-7bf6-463a-85e1-26c9e791dd60" />
</center>

- The first device could be an access switch or even a VoIP phone, just as long as it's configured to trust the ingress traffic and set the values for CoS and DSCP.

Knowing the line between what devices we trust and don’t trust for configuration changes matters, and it especially matters for QoS.

### Marking Values

We won’t go deep into all possible marking configurations in this lab (or on the CCNA), but we’ll look at the most important ones conceptually and do a simple marking demo. Let’s first take a look at the three sets of DSCP values that are adjusted in DiffServ next:

**Expedited Forwarding (EF)**

Our first DSCP value we will look at is:

- **Expedited Forwarding (EF)**: A single value used for packets that need low latency (delay), low jitter, and low loss (DSCP value is decimal 46).

This one is pretty self-explanatory; we want traffic sent as quickly and efficiently as possible without any hiccups along the way. A great example of this in practice is voice traffic.

**Assured Forwarding (AF)**

Now, we’ll need to visualize how different traffic is prioritized by what’s considered the most and least valued traffic:

- **Assured Forwarding (AF)**:  Defined as a set of 12 DSCP values, with four separate queues and three levels of drop priority within each queue.

This one is a bit easier to understand with a table:

<center>
  <img width="400" height="400" alt="assured_forwarding" class="center" src="https://github.com/user-attachments/assets/4823b9ac-86c7-4634-acd9-f1dffd7c9505" />
</center>


- The AF table above is structured as AFXY, where X refers to the queue (1 through 4) and Y refers to the drop priority (1 through 3).

For example. AF11, AF12, and AF13 are all part of a queue; AF21, AF22, and AF23 are part of another, and so on. As well as treating AF11, AF21, etc. with preferred drop treatment (not as dropped), while AF13, AF23, etc. are treated with the worst drop treatment (most dropped). It really depends on the congestion avoidance drop actions that we will get into later in this lab.

**Class Selector (CS)**

Lastly, we have our last DSCP value:

- **Class Selector (CS)**: A method to classify traffic by its DSCP values, which are backward-compatible with the older IPP model.

Remember, IPP has been replaced with DSCP, but CS will take IPP’s 3-bit values. Let’s take a look at how the IPv4 DSCP field uses the IPP values with the CS:

<center>
  <img width="400" height="400" alt="class_selector" class="center" src="https://github.com/user-attachments/assets/60965f20-f819-46c0-bfa7-ce28c753bf6e" />
</center>

| **IPP** | **CS** | **Decimal DSCP** | **IPP Names** |
| --- | --- | --- | --- |
| 000 | CS0 | 000000 | Routine  |
| 001 | CS1 | 001000 | Priority |
| 010 | CS2 | 010000 | Immediate |
| 011 | CS3 | 011000 | Flash |
| 100 | CS4 | 100000 | Flash Override |
| 101 | CS5 | 10100 | Critic/Critical |
| 110 | CS6 | 110000 | Internetwork Control |
| 111 | CS7 | 111000 | Network Control |

We will build upon these concepts in classification and marking with the rest of the lab, seeing how traffic is prioritized based on queueing, policy, shaping, and congestion avoidance. Next, up, let’s see if we can implement both QoS on the homelab devices as well as configure a priority marking configuration.

### Enabling QoS

Alright, enough with concepts, let's configure something. Before we start applying QoS policies, we can enable QoS to see how it classifies the traffic:

**SW1/SW2/SW3**

```bash
conf t
!
mls qos
!
end
wr
```

**Verify**

```bash
show mls qos
show mls qos maps dscp-cos
```

- We should see default mappings between the DSCP values (0-63) and CoS priorities (0-7).

Like this:

```bash
SW1#show mls qos
QoS is enabled
QoS ip packet dscp rewrite is enabled
```

```bash
SW1#show mls qos maps dscp-cos
Dscp-cos map:
d1 :  d2 0  1  2  3  4  5  6  7  8  9
---------------------------------------
0 :    00 00 00 00 00 00 00 00 01 01
1 :    01 01 01 01 01 01 02 02 02 02
2 :    02 02 02 02 03 03 03 03 03 03
3 :    03 03 04 04 04 04 04 04 04 04
4 :    05 05 05 05 05 05 05 05 06 06
5 :    06 06 06 06 06 06 07 07 07 07
6 :    07 07 07 07
```

From here, we can start configuring QoS policies, applying one policy per QoS topic. Let’s configure a marking next.

### Priority Marking Demo

To showcase QoS Marking, we will mark all SSH traffic from my PC to SW1. This is because marking is defined by our trust boundary, which is done as close to the source as possible.

To do this, we will mark SSH traffic with DSCP EF (46) - here’s how we’ll do it:

**SW1**

```bash
conf t
!
class-map match-any SSH-TRAFFIC
 match protocol ssh
exit
!
policy-map MARK-SSH
 class SSH-TRAFFIC
  set dscp ef
 class class-default
  set dscp default
exit
!
interface Fa0/3
 service-policy input MARK-SSH
exit
!
end
wr
```

Command Breakdown:

- `class-map match-any SSH-TRAFFIC`:  Creates a class map named SSH-TRAFFIC
- `match protocol ssh`: Matches SSH traffic to it by protocol, by deep packet inspection.
- `policy-map MARK-SSH`: Creates a policy map named MARK SSH, which also holds different classes of the map.
- `class SSH-TRAFFIC`: Any traffic inside the SSH-TRAFFIC class, mark it.
- `set dscp ef`: We’re marking DSCP with EF (Expedited Forwarding) for low-latency/ priority traffic.
- `set dscp default`: All other traffic is DSCP 0, meaning all traffic other than SSH is considered lower priority.
- `service-policy input MARK-SSH`: Applied the policy on the inbound interface connected to my PC.

**Verify**

```bash
show policy-map MARK-SSH
show policy-map interface Fa0/3
```

- As long as we SSH into the device, we should see packets matching under the `SSH-TRAFFIC` class map.

Up next, let’s take a look at queuing in QoS and how it’s used on interface links on an enterprise network.

## **Queue Behavior**

A queue in computer networking is a message going out of a network interface. These messages can build up, where they’ll have to wait until the outgoing interface is available. 

- **Queuing**: A QoS toolset that manages the queues that hold packets while they wait their turn to exit an interface.

Here is a visual representation of what a queue looks like on an interface:

<center>
  <img width="400" height="400" alt="tail_drop" class="center" src="https://github.com/user-attachments/assets/57dbb01f-83ed-4594-a703-3d3d4d6350fd" />
</center>

- Routers may have other actions as well, like the ingress ACL, ingress NAT, egress ACLs after the forwarding decision, etc.

In computer networking, this is considered a “first in, first out” (FIFO) scheduler. And sometimes networking devices have a queueing system with multiple queues happening at the same time. 

For this to happen, a Classifier is used to funnel the packets into their appropriate queues, as well as prioritize which packets go into what queues. One important Classifier we can take a look at is: **Round-Robin**.

### Round-Robin

Used by Cisco routers/switches, the Round-Robin Classifer is:

- **Round Robin**: Cycles through different queues, in order, taking turns applying packets to different queues, based on priority.

Here’s a simple visual of this process:

<center>
  <img width="400" height="400" alt="round_robin" class="center" src="https://github.com/user-attachments/assets/7596cc9d-7ae2-4948-b90a-25e654f4ac0c" />
</center>

Round-Robin also uses a concept of *weighing*, or *weighted round robin* (WRR), where the scheduler takes a different number of packets from each queue, and gives more preference to one queue versus another. This process looks something like this:

<center>
  <img width="400" height="400" alt="weighted_round_robin" class="center" src="https://github.com/user-attachments/assets/1cb76462-b082-4893-b2da-e8f9529c08eb" />
</center>

- As you can see, we have three different queues, with square purple packets in each queue labeled with different numbers. WRR will go through each queue, in order, and prioritize the queues (which is why it goes by weight 1, 2, and 3 in the final queue).

This concept is important, but what happens with video or voice, where we don’t want low latency, jitter, or loss? Dividing up the packets into different queues for them to be thrown together with a lower priority doesn’t make sense. That’s where Low Latency Queuing can help us next.

### Low Latency

A round-robin queuing system adds too much delay for voice and video packets to function effectively. Even if you had a “Voice/Video” queue, round-robin still goes through each queue IN ORDER, so that won’t help us. That’s where Low Latency Queuing (LLQ) can help:

- **Low Latency Queuing (LLQ)**: Tells the scheduler to treat one or more queues with priority.

Think of LLQ as the Disney FastPass; it will get you to the front of the line because you paid for priority, just like how voice/video takes priority over other forms of data transmission.

Here’s a great image to showcase LLQ:

<center>
  <img width="400" height="400" alt="low-latency-queuing" class="center" src="https://github.com/user-attachments/assets/26c3c4cc-4281-48bf-912d-c5f5a8acd3b7" />
</center>

- Here, our video/voice traffic would be in “Output Queue #1

However, we run into another issue. What if the speed of the voice/video traffic matches that of the speed of the interface (bandwidth)? Well, none of our other queues would be served, called *queue starvation*. We can use *policing*, which we’ll take a look at next, but we need a way to limit the amount of voice/video that the network routes, so our policer doesn’t discard the traffic. That answer lies in **Call Admission Control (CAC),** which the CCNP covers.

Up next, let’s take a look at how queueing works on Cisco hardware with my demo for this concept below.

### Queue Demo

We now know that QoS queuing mechanisms act on the way out (egress) of an interface, not on ingress. To demonstrate this, we will apply our queueing to R1’s Gi0/0 interface to direct and give a flow direction to our SSH packets for a beginner queueing example. Let’s see how this works:

**R1**

```bash
conf t
!
class-map match-any SSH-TRAFFIC
 match protocol ssh
exit
!
policy-map QUEUING-DEMO
 class SSH-TRAFFIC
  priority percent 10
 class class-default
  bandwidth percent 90
exit
!
interface GigabitEthernet0/0
 service-policy output QUEUING-DEMO
exit
!
end
wr
```

Command Breakdown:

- `priority`: enabled Low Latency Queueing (LLQ), so traffic jumps to the front of the queue.
- `perfect 10`:  Gives SSH a strict priority queue and reserves 10% of the interface bandwidth during times of congestion.
- `bandwidth percent 90`: All other traffic shares the remaining 90% with fair scheduling.

**Verify**

```bash
show policy-map QUEUING-DEMO
show policy-map interface GigabitEthernet0/0
```

- You’ll have to SSH into SW2 or SW3 to see match packets for SSH to start ticking up.

Now, with our application of queueing to R1’s Gi0/0, we can prioritize traffic in egress interface queues. Up next, let’s take a look at shaping and policing.

## **Traffic Shaping & Policing**

Shaping and Policing are a bit of a unique QoS feature, where most of the configuration for both of them happens at the WAN edge routers. Both monitor the bit rate that passes through them as well as measure the number of bits over time. If these measurements push the devices to a point of exceeding the limits on these rates, then shapers or policers will either queue the packets or drop them entirely, to not overwhelm the routers. Let’s see how both of these QoS tools help monitor the network.

### Policing

We can safely assume incoming traffic to the network can vary, especially at the rate at which it’s processed. Policers kind of do what they are defined as in the network:

- **Policers**: Drop or re-mark incoming or outgoing traffic that goes beyond the desired traffic rate.
- **Committed Information Rate (CIR)**: Defines the maximum bandwidth that can be transmitted over an interface.

Below, we see a graph with our time on the x-axis and traffic transmitted on the y-axis:

<center>
  <img width="400" height="400" alt="policing" class="center" src="https://github.com/user-attachments/assets/439036ae-f901-4008-b3d4-46704cd548a4" />
</center>

- The middle horizontal dotted red line is the CIR, where the policer discards any messages that push the rate over the policing line.

Some bursts of traffic may happen, but for the most part, the policer will have a limit that the traffic shouldn’t exceed, with a few exceptions. This is especially practical for ISPs that have a limit on traffic speeds for their customers.

Policing is typically configured on the ingress of the WAN link interface (incoming). Also, instead of flat-out discarding traffic, the policer can re-mark the traffic and have it pushed through into the network.

### Shaping

Another solution to the traffic rate problem is to also consider slowing down the traffic that comes in, right? That’s where a shaper can come into play on a network as well:

- **Shaper**: A rate-limiting technique that buffers excessive traffic instead of discarding it.

Below is another similar graph, but with a different outcome:

<center>
  <img width="400" height="400" alt="policing" class="center" src="https://github.com/user-attachments/assets/86e072a6-669b-44aa-9f4a-b39a772e25b7" />
</center>

- In this figure, instead of the traffic being dropped after it exceeds the CIR, it’s placed in a shaping buffer to be sent later.

This is more difficult to do with voice or video traffic, since there would be an increase in jitter and delay. Instead, we use a time interval to allocate enough bits to be sent at just the right time, and then wait for enough time to not cause jitter or delay to be an issue. 

Shaping is typically configured on the egress of the WAN link interface (outgoing). We can simulate these types of shaping and policing configurations in our homelab next!

### Shaping and Policing Demos

**Policing**

For policing, we essentially want there to be a limit that traffic can’t exceed, and if it does, then it’ll be dropped immediately. Let’s apply this to R1’s Gi0/0 interface, since this is like our NAT “WAN” link between the internal and “ISP” of my homelab. Let’s take a look:

**R1**

```bash
conf t
!
policy-map POLICING-DEMO
 class class-default
  police 1000000 conform-action transmit exceed-action drop
exit
!
interface GigabitEthernet0/0
 no service-policy output QUEUING-DEMO
 service-policy output POLICING-DEMO
exit
!
end
wr
```

Command Breakdown:

- `police 1000000 conform-action transmit exceed-action drop:`
    - `1000000`CIR (Committed Information Rate) is a 1,000,000 bps (or 1 Mb/s) rate, allowing this through the class.
    - `conform-action transmit`:  Traffic at or under 1 Mbps is forwarded normally.
    - `exceed-action drop`: Anything above that is dropped immediately.

**Verify**

```
show policy-map POLICING-DEMO
show policy-map interface GigabitEthernet0/0
```

- To see conform/exceed counters on the interface, however, I won’t be simulating high traffic in this lab.

Now that we have our queueing policy configured, let’s move on to shaping and how that configuration differs.

**Shaping**

We will be configuring R1’s Gi0/0 interface again, same as the queuing policy. We will be removing the policing service policy on the interface and swapping it with the shaping service policy:

**R1**

```bash
conf t
!
policy-map SHAPING-DEMO
 class class-default
  shape average 1000000
exit
!
interface GigabitEthernet0/0
 no service-policy output POLICING-DEMO
 service-policy output SHAPING-DEMO
exit
!
end
wr
```

Command Breakdown:

- `shape average 1000000`: Shapes traffic at an average of 1Mbps, using buffers that exceed the rate instead of dropping them immediately.

**Verify**

```bash
show policy-map SHAPING-DEMO
show policy-map interface GigabitEthernet0/0
```

- Checking the interface, we can see that there is now a queue limit as well as a depth/drop total.

Fairly simple configuration all around, shaping and policing migrate the traffic and determine how an interface should handle large amounts of traffic. Next, let’s see how we go about avoiding traffic congestion altogether.

## **Congestion Avoidance**

When it comes to congestion in a queue, the more congestion equates to delays, loss, and overall negative impact on a network. This is where QoS shines in its feature:

- **Congestion Avoidance**: Attempts to reduce packet loss by discarding some packets in TCP connections.

At first, this seems counterintuitive. Don’t we want to preserve every TCP packet and not drop them? In practice, having selective drops is necessary for flow control. When queues become overfilled, a last resort is to drop packets, but there are reasons behind this approach. Let’s take a look at a few.

### Windowing

Between a host and a receiver in a TCP connection, the rate at which they send/receive data is based on the receiver’s ability to process this data. The flow at which it’s controlled is called:

- **Windowing**: The flow control at which a TCP connection sends/receives data.
    - Imagine windowing as filling up your glass of water from the fridge. Your fridge is the flow, and your cup is the queue.

This window can be adjusted; for every TCP segment lost, the window can shrink, and for every TCP segment gained, it can increase in size.

**Tail Drop**

One concept in windowing is tail drop, where a router’s queue is filled, and any new IP packets will be dropped since the router can’t process the queue:

<center>
  <img width="400" height="400" alt="tail_drop" class="center" src="https://github.com/user-attachments/assets/309abd21-1312-43b5-aba7-cde07cc7757e" />
</center>

Congestion avoidance strategies like **Random Early Detection (RED)** and **Weighted Random Early Detection (WRED)** are concepts that are explored in the CCNP ENCOR. They’re configured to drop random packets when the queue starts to get filled up on a router.

That’s a perfect transition into our congestion avoidance demo, where we will configure this concept on the homelab.

### **Congestion Avoidance Demo**

To finish out all of our demos, we’re going to configure WRED on R1’s Gi0/0 interface to showcase congestion avoidance.

**R1**

```bash
conf t
!
policy-map CONGESTION-DEMO
 class class-default
  random-detect dscp-based
exit
!
interface GigabitEthernet0/0
 no service-policy output SHAPING-DEMO
 service-policy output CONGESTION-DEMO
exit
!
end
wr
```

Command Breakdown:

- `random-detect dscp-based`: This enables WRED (Weighted Random Early Detection on the default class.

**Verify**

```bash
show policy-map CONGESTION-DEMO
show policy-map interface GigabitEthernet0/0
```

- You should see that congestion avoidance now lives on the egress interface of R1’s Gi0/0, pretty cool, right?

That’s it! With this last demo, we’ve configured all of the major QoS concepts on the home lab. Even though we didn’t simulate these concepts in action, this is more than sufficient for the CCNA.

## Wrap-Up

QoS is a fundamental concept that helps us understand how networks deliver consistent performance that may be tailored to specific business needs or how network traffic can be more efficient by prioritizing what matters to an enterprise. From marking, to queueing, policing/shaping, and congestion avoidance, all of it works together so well that we don’t even notice the behind-the-scenes tools that regulate network traffic until we put a magnifying glass to the features QoS supplies. 

This was more of a conceptual lab, with little configuration applied. This may be expanded upon when/if I decide to get my CCNP ENCOR certification, but this is perfect to help me understand these concepts better for the CCNA.
